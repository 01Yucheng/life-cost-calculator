import streamlit as st
import pandas as pd
from github import Github
import io
import base64
from PIL import Image
import urllib.parse
import re
import json
import google.generativeai as genai

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="ä¸œäº¬ç”Ÿæ´»æˆæœ¬ AI è®¡ç®—å™¨", layout="wide", page_icon="ğŸ—¼")

# --- 2. GitHub å­˜å‚¨é€»è¾‘ ---
class GitHubStorage:
    def __init__(self):
        try:
            self.g = Github(st.secrets["github"]["token"])
            self.repo = self.g.get_repo(st.secrets["github"]["repo"])
            self.file_path = st.secrets["github"].get("file_path", "housing_data.csv")
            self.branch = st.secrets["github"].get("branch", "main")
        except Exception as e:
            st.error(f"GitHub é…ç½®é”™è¯¯: {e}")
            st.stop()

    def load_data(self):
        try:
            content = self.repo.get_contents(self.file_path, ref=self.branch)
            return pd.read_csv(io.StringIO(content.decoded_content.decode('utf-8-sig')))
        except:
            return pd.DataFrame(columns=[
                "æˆ¿æºåç§°", "æˆ¿æºä½ç½®", "æˆ¿æºå›¾ç‰‡", "æœˆæˆ¿ç§Ÿ(å††)", "ç®¡ç†è´¹(å††)", 
                "å­¦æ—¶(åˆ†)", "å­¦è´¹(å•ç¨‹)", "å¡¾æ—¶(åˆ†)", "å¡¾è´¹(å•ç¨‹)", "çº¿è·¯æ¦‚è¦"
            ])

    def save_data(self, df):
        csv_content = df.to_csv(index=False, encoding='utf-8-sig')
        try:
            contents = self.repo.get_contents(self.file_path, ref=self.branch)
            self.repo.update_file(self.file_path, "Update data", csv_content, contents.sha, branch=self.branch)
        except:
            self.repo.create_file(self.file_path, "Initial data", csv_content, branch=self.branch)

# --- 3. åˆå§‹åŒ– ---
storage = GitHubStorage()

if "df_houses" not in st.session_state:
    st.session_state.df_houses = storage.load_data()

@st.cache_resource
def init_ai():
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    return genai.GenerativeModel("models/gemini-1.5-flash")

model = init_ai()

# --- 4. å·¥å…·å‡½æ•° ---
def compress_img(uploaded_file):
    if uploaded_file is None: return ""
    img = Image.open(uploaded_file)
    img.thumbnail((400, 400)) # å‹ç¼©å°ºå¯¸
    buf = io.BytesIO()
    img.save(buf, format="JPEG", quality=75) # é™ä½è´¨é‡ä»¥å‡å°ä½“ç§¯
    return f"data:image/jpeg;base64,{base64.b64encode(buf.getvalue()).decode()}"

def get_transit(origin, destination):
    prompt = f"æ—¥æœ¬äº¤é€šåˆ†æ JSONï¼šèµ·ç‚¹[{origin}]ï¼Œç»ˆç‚¹[{destination}]ã€‚è¿”å›:{{'mins':æ•´æ•°,'yen':æ•´æ•°,'line':'ç®€è¿°'}}"
    try:
        response = model.generate_content(prompt)
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        return json.loads(match.group()) if match else None
    except: return None

# --- 5. UI å¸ƒå±€ ---
st.title("ğŸ—¼ ä¸œäº¬ç”Ÿæ´»æˆæœ¬ AI è®¡ç®—å™¨")

# ä¾§è¾¹æ ï¼šå‚æ•°è®¾ç½®
with st.sidebar:
    st.header("âš™ï¸ ç”Ÿæ´»å‚æ•°")
    base_living = st.number_input("ğŸ” æœˆå›ºå®šç”Ÿæ´»è´¹ (ä¼™é£Ÿ/æ‚é¡¹)", value=60000, step=5000)
    days_school = st.slider("ğŸ« å­¦æ ¡é€šå‹¤ (å¤©/å‘¨)", 1, 7, 5)
    days_juku = st.slider("ğŸ¨ ç§å¡¾é€šå‹¤ (å¤©/å‘¨)", 0.0, 7.0, 0.5, step=0.5)
    st.divider()
    dest_school = st.text_input("ğŸ“ å­¦æ ¡ä½ç½®", value="ä¸œäº¬éƒ½æ–°å®¿åŒºç™¾äººç”º2-24-12")
    dest_juku = st.text_input("ğŸ“ ç§å¡¾ä½ç½®", value="ä¸œäº¬éƒ½è’å·åŒºè¥¿æ—¥æš®é‡Œ2-12-5")

# A. å½•å…¥åŒº
with st.expander("â• å½•å…¥æ–°æˆ¿æº", expanded=True):
    c1, c2 = st.columns([2, 1])
    with c1:
        n_col, l_col, r_col = st.columns(3)
        name_in = n_col.text_input("ğŸ  æˆ¿æºåç§°")
        loc_in = l_col.text_input("ğŸ“ è½¦ç«™å")
        rent_in = r_col.number_input("ğŸ’° é¢„ä¼°æœˆç§Ÿ", value=80000, step=1000)
    with c2:
        uploaded_file = st.file_uploader("ğŸ–¼ï¸ æˆ¿æºç…§ç‰‡", type=['jpg','jpeg','png'])

    if st.button("ğŸš€ AI åˆ†æå¹¶ä¿å­˜", use_container_width=True):
        if loc_in:
            with st.spinner("AI æ­£åœ¨è®¡ç®—é€šå‹¤å¼€é”€..."):
                s_data = get_transit(loc_in, dest_school)
                j_data = get_transit(loc_in, dest_juku)
                img_data = compress_img(uploaded_file)
                
                if s_data and j_data:
                    new_row = pd.DataFrame([{
                        "æˆ¿æºåç§°": name_in or f"{loc_in}æˆ¿æº",
                        "æˆ¿æºä½ç½®": loc_in,
                        "æˆ¿æºå›¾ç‰‡": img_data,
                        "æœˆæˆ¿ç§Ÿ(å††)": rent_in,
                        "ç®¡ç†è´¹(å††)": 5000,
                        "å­¦æ—¶(åˆ†)": s_data['mins'],
                        "å­¦è´¹(å•ç¨‹)": s_data['yen'],
                        "å¡¾æ—¶(åˆ†)": j_data['mins'],
                        "å¡¾è´¹(å•ç¨‹)": j_data['yen'],
                        "çº¿è·¯æ¦‚è¦": s_data['line']
                    }])
                    st.session_state.df_houses = pd.concat([st.session_state.df_houses, new_row], ignore_index=True)
                    storage.save_data(st.session_state.df_houses)
                    st.rerun()

# B. æ•°æ®æ¸…å•
st.subheader("ğŸ“ æˆ¿æºæ•°æ®æ¸…å•")
edited_df = st.data_editor(
    st.session_state.df_houses, 
    num_rows="dynamic", 
    use_container_width=True,
    column_config={"æˆ¿æºå›¾ç‰‡": st.column_config.ImageColumn("é¢„è§ˆ")},
    key="main_editor"
)

# è‡ªåŠ¨åŒæ­¥æ”¹åŠ¨
if not edited_df.equals(st.session_state.df_houses):
    st.session_state.df_houses = edited_df
    storage.save_data(edited_df)
    st.toast("âœ… å·²åŒæ­¥è‡³ GitHub")

# C. å¯¹æ¯”æŠ¥å‘Š (ä¼˜åŒ– PDF å¯¼å‡ºæ ·å¼)
if not st.session_state.df_houses.empty:
    st.divider()
    st.subheader("ğŸ“Š æˆ¿æºå¼€é”€å¯¹æ¯”åˆ†ææŠ¥å‘Š")
    
    # CSS: é˜²æ­¢æ‰“å°æ—¶å¡ç‰‡è¢«æˆªæ–­
    st.markdown("""
        <style>
        @media print {
            .stContainer { break-inside: avoid; border: 1px solid #eee !important; margin-bottom: 20px !important; }
            .stButton { display: none !important; } /* æ‰“å°æ—¶ä¸æ˜¾ç¤ºæŒ‰é’® */
        }
        </style>
    """, unsafe_allow_html=True)

    for idx, row in st.session_state.df_houses.iterrows():
        try:
            # åŠ¨æ€è®¡ç®—
            rent_total = float(row["æœˆæˆ¿ç§Ÿ(å††)"]) + float(row["ç®¡ç†è´¹(å††)"])
            commute_m = (float(row["å­¦è´¹(å•ç¨‹)"]) * 2 * days_school + float(row["å¡¾è´¹(å•ç¨‹)"]) * 2 * days_juku) * 4.33
            total_m = rent_total + commute_m + base_living
            
            with st.container(border=True):
                i_col, t_col, b_col = st.columns([1.5, 3, 1])
                with i_col:
                    if row["æˆ¿æºå›¾ç‰‡"]: st.image(row["æˆ¿æºå›¾ç‰‡"], use_container_width=True)
                with t_col:
                    st.markdown(f"### {row['æˆ¿æºåç§°']} ({row['æˆ¿æºä½ç½®']})")
                    st.markdown(f"#### ğŸ’° é¢„ä¼°æœˆæ€»æ”¯å‡º: **{int(total_m):,} å††**")
                    st.write(f"ğŸ  æˆ¿ç§Ÿ+ç®¡ç†: {int(rent_total):,} | ğŸš‡ æœˆé€šå‹¤è´¹: {int(commute_m):,}")
                    st.caption(f"çº¿è·¯: {row['çº¿è·¯æ¦‚è¦']}")
                with b_col:
                    m_api = "https://www.google.com/maps/dir/?api=1"
                    s_url = f"{m_api}&origin={urllib.parse.quote(row['æˆ¿æºä½ç½®'])}&destination={urllib.parse.quote(dest_school)}&travelmode=transit"
                    j_url = f"{m_api}&origin={urllib.parse.quote(row['æˆ¿æºä½ç½®'])}&destination={urllib.parse.quote(dest_juku)}&travelmode=transit"
                    st.link_button("ğŸ« å­¦æ ¡åœ°å›¾", s_url, use_container_width=True)
                    st.link_button("ğŸ¨ ç§å¡¾åœ°å›¾", j_url, use_container_width=True)
                    if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"del_card_{idx}", use_container_width=True):
                        st.session_state.df_houses = st.session_state.df_houses.drop(idx).reset_index(drop=True)
                        storage.save_data(st.session_state.df_houses)
                        st.rerun()
        except: continue

if st.button("ğŸš¨ æ¸…ç©ºæ‰€æœ‰äº‘ç«¯æ•°æ®"):
    st.session_state.df_houses = pd.DataFrame(columns=st.session_state.df_houses.columns)
    storage.save_data(st.session_state.df_houses)
    st.rerun()
