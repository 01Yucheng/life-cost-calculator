import streamlit as st
import pandas as pd
import google.generativeai as genai
import json
import re
import urllib.parse
import base64
from github import Github, Auth
from io import BytesIO
from PIL import Image

# --- 1. é…ç½®ä¸ AI åˆå§‹åŒ– ---
st.set_page_config(page_title="ä¸œäº¬ç”Ÿæ´»æˆæœ¬ AI è®¡ç®—å™¨ Pro", layout="wide", page_icon="ğŸ—¼")

@st.cache_resource
def init_ai():
    if "GEMINI_API_KEY" not in st.secrets:
        st.error("ğŸ”‘ æœªåœ¨ Secrets ä¸­æ‰¾åˆ° GEMINI_API_KEY")
        st.stop()
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    try:
        # ç»Ÿä¸€ä½¿ç”¨ flash æ¨¡å‹
        return genai.GenerativeModel("gemini-1.5-flash")
    except Exception as e:
        st.error(f"AI åˆå§‹åŒ–å¤±è´¥: {e}")
        st.stop()

model = init_ai()

# --- 2. GitHub æ•°æ®åŒæ­¥å·¥å…· ---
def get_github_repo():
    try:
        auth = Auth.Token(st.secrets["GITHUB_TOKEN"])
        g = Github(auth=auth)
        return g.get_repo(st.secrets["REPO_NAME"])
    except Exception as e:
        st.error(f"GitHub è¿æ¥å¤±è´¥: {e}")
        return None

def load_data_from_github():
    cols = [
        "æˆ¿æºåç§°", "æˆ¿æºä½ç½®", "æˆ¿æºå›¾ç‰‡", "æœˆæˆ¿ç§Ÿ(å††)", "ç®¡ç†è´¹(å††)", 
        "åˆæœŸèµ„é‡‘æŠ•å…¥", "åˆæœŸè´¹ç”¨æ˜ç»†", "é¢ç§¯", "æˆ·å‹",
        "å­¦æ—¶(åˆ†)", "å­¦è´¹(å•ç¨‹)", "å­¦å®šæœŸ(æœˆ)", 
        "å¡¾æ—¶(åˆ†)", "å¡¾è´¹(å•ç¨‹)", "å¡¾å®šæœŸ(æœˆ)"
    ]
    try:
        repo = get_github_repo()
        if repo:
            file_content = repo.get_contents("house_data.csv")
            # å…³é”®ï¼šå¤„ç† utf-8-sig
            df = pd.read_csv(BytesIO(file_content.decoded_content), encoding='utf-8-sig')
            df.columns = [c.strip() for c in df.columns]
            for c in cols:
                if c not in df.columns: df[c] = ""
            # ç±»å‹ä¿®æ­£
            num_cols = ["æœˆæˆ¿ç§Ÿ(å††)", "ç®¡ç†è´¹(å††)", "åˆæœŸèµ„é‡‘æŠ•å…¥", "å­¦è´¹(å•ç¨‹)", "å­¦å®šæœŸ(æœˆ)", "å¡¾æ—¶(åˆ†)", "å¡¾è´¹(å•ç¨‹)", "å¡¾å®šæœŸ(æœˆ)"]
            for col in num_cols:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
            df["æˆ¿æºå›¾ç‰‡"] = df["æˆ¿æºå›¾ç‰‡"].fillna("")
            return df[cols]
    except:
        return pd.DataFrame(columns=cols)
    return pd.DataFrame(columns=cols)

def save_data_to_github(df):
    repo = get_github_repo()
    if not repo: return
    csv_string = df.to_csv(index=False, encoding='utf-8-sig')
    try:
        contents = repo.get_contents("house_data.csv")
        repo.update_file(contents.path, "Update house data", csv_string, contents.sha)
        st.success("âœ… æ•°æ®å·²åŒæ­¥è‡³ GitHub!")
    except:
        repo.create_file("house_data.csv", "Initial commit", csv_string)
        st.success("ğŸš€ GitHub æ•°æ®åº“å·²åˆå§‹åŒ–!")

# --- 3. å·¥å…·å‡½æ•° ---
def safe_int(val):
    try:
        if val is None or (isinstance(val, float) and pd.isna(val)) or val == "": 
            return 0
        return int(float(val))
    except: return 0

def analyze_house_image(uploaded_file):
    try:
        img = Image.open(uploaded_file)
        prompt = "ä½œä¸ºæ—¥æœ¬ä¸åŠ¨äº§ä¸“å®¶ï¼Œè¯·ä»å›¾ä¸­æå–ä¿¡æ¯å¹¶è¿”å›JSONæ ¼å¼ï¼ˆname, station, rent, admin, initial_total, area, layout, detailsï¼‰ã€‚ä¸è¦åŒ…å«Markdownä»£ç å—å¤–å£³ã€‚"
        response = model.generate_content([prompt, img])
        # å¢å¼º JSON æå–é€»è¾‘
        clean_text = re.search(r'\{.*\}', response.text, re.DOTALL).group()
        return json.loads(clean_text)
    except: return None

def get_transit(origin, destination):
    if not origin or origin.strip() == "": return {"mins": 0, "yen": 0, "pass": 0}
    prompt = f"è®¡ç®—ä»[{origin}]åˆ°[{destination}]é€šå‹¤ï¼Œè¿”å›JSON: {{\"mins\": æ•´æ•°, \"yen\": å•ç¨‹, \"pass\": æœˆå®šæœŸ}}"
    try:
        response = model.generate_content(prompt)
        clean_text = re.search(r'\{.*\}', response.text, re.DOTALL).group()
        return json.loads(clean_text)
    except: return {"mins": 0, "yen": 0, "pass": 0}

# --- 4. UI ç•Œé¢ ---
st.title("ğŸ—¼ ä¸œäº¬ç”Ÿæ´»æˆæœ¬ AI è®¡ç®—å™¨ Pro")

if "df_houses" not in st.session_state:
    st.session_state.df_houses = load_data_from_github()

# --- å½•å…¥æ–°æˆ¿æºé€»è¾‘ä¿®å¤ ---
with st.expander("â• å½•å…¥æ–°æˆ¿æº", expanded=True):
    up_file = st.file_uploader("ğŸ–¼ï¸ ä¸Šä¼ æˆ¿æºè¯¦æƒ…å›¾", type=['png', 'jpg', 'jpeg'], key="main_house_uploader")
    if "ai_cache" not in st.session_state:
        st.session_state.ai_cache = {"name": "", "station": "", "rent": 0, "admin": 0, "initial": 0, "details": "", "area": "", "layout": ""}

    if up_file and st.button("ğŸ” AI æ‰«ææˆ¿æºå›¾"):
        with st.spinner("AI è¯†åˆ«ä¸­..."):
            res = analyze_house_image(up_file)
            if res:
                st.session_state.ai_cache.update({
                    "name": res.get("name", ""), "station": res.get("station", ""),
                    "rent": res.get("rent", 0), "admin": res.get("admin", 0),
                    "initial": res.get("initial_total", 0), "details": res.get("details", ""),
                    "area": str(res.get("area", "")), "layout": res.get("layout", "")
                })

    # è¡¨å•éƒ¨åˆ†ä¿æŒåŸæ ·...
    # (æ­¤å¤„çœç•¥ä¸­é—´è¡¨å•ä»£ç ï¼Œé€»è¾‘ä¸ä½ åŸä»£ç ä¸€è‡´)
    
    # æ ¸å¿ƒä¿®å¤ï¼šä¿å­˜æ—¶çš„å›¾ç‰‡å¤„ç†
    if st.button("ğŸš€ è®¡ç®—å¹¶ä¿å­˜åˆ°äº‘ç«¯", type="primary"):
        # ... (å‰ç½®é€»è¾‘)
        with st.spinner("æ­£åœ¨å¤„ç†..."):
            img_b64 = ""
            if up_file:
                # ä¿®å¤ç‚¹ï¼šå‹ç¼©å›¾ç‰‡é˜²æ­¢æ–‡ä»¶è¿‡å¤§
                img_temp = Image.open(up_file)
                img_temp.thumbnail((800, 800)) 
                buf = BytesIO()
                img_temp.convert("RGB").save(buf, format="JPEG", quality=75)
                img_b64 = f"data:image/jpeg;base64,{base64.b64encode(buf.getvalue()).decode()}"
            
            # ... (ç”Ÿæˆ new_row é€»è¾‘)
            st.session_state.df_houses = pd.concat([st.session_state.df_houses, pd.DataFrame([new_row])], ignore_index=True)
            save_data_to_github(st.session_state.df_houses)
            st.rerun()

# --- æ•°æ®æ¸…å•è¡¨åŒæ­¥ä¿®å¤ ---
st.subheader("ğŸ“ æˆ¿æºæ•°æ®æ¸…å•")
# è¿™é‡Œçš„ edited_df éœ€è¦åœ¨åç»­é€»è¾‘ä¸­æ›¿ä»£ st.session_state.df_houses è¿›è¡ŒæŠ¥å‘Šè®¡ç®—
edited_df = st.data_editor(
    st.session_state.df_houses, 
    num_rows="dynamic", 
    use_container_width=True, 
    key="main_data_editor"
)
# å…³é”®ï¼šç¡®ä¿ç¼–è¾‘å™¨ä¿®æ”¹åçš„æ•°æ®ç«‹å³ç”Ÿæ•ˆ
st.session_state.df_houses = edited_df 

# ... (åç»­æŠ¥å‘Šå±•ç¤ºé€»è¾‘ä¿æŒä¸å˜)
