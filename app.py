import streamlit as st
import pandas as pd
from github import Github
import io
import base64
from PIL import Image
import urllib.parse
import re
import json
import google.generativeai as genai

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="ä¸œäº¬ç”Ÿæ´»æˆæœ¬ AI è®¡ç®—å™¨", layout="wide", page_icon="ğŸ—¼")

# --- 2. GitHub å­˜å‚¨é€»è¾‘ ---
class GitHubStorage:
    def __init__(self):
        try:
            self.g = Github(st.secrets["github"]["token"])
            self.repo = self.g.get_repo(st.secrets["github"]["repo"])
            self.file_path = "housing_data.csv"
        except Exception as e:
            st.error("âŒ GitHub é…ç½®é”™è¯¯ï¼Œè¯·æ£€æŸ¥ Secrets")
            st.stop()

    def load_data(self):
        try:
            content = self.repo.get_contents(self.file_path)
            return pd.read_csv(io.StringIO(content.decoded_content.decode('utf-8-sig')))
        except:
            return pd.DataFrame(columns=["æˆ¿æºåç§°", "æˆ¿æºä½ç½®", "æˆ¿æºå›¾ç‰‡", "æœˆæˆ¿ç§Ÿ(å††)", "ç®¡ç†è´¹(å††)", "å­¦è´¹(å•ç¨‹)", "å¡¾è´¹(å•ç¨‹)", "é€šå‹¤æ—¶é—´"])

    def save_data(self, df):
        csv_content = df.to_csv(index=False, encoding='utf-8-sig')
        try:
            contents = self.repo.get_contents(self.file_path)
            self.repo.update_file(self.file_path, "update", csv_content, contents.sha)
        except:
            self.repo.create_file(self.file_path, "init", csv_content)

# --- 3. AI åˆå§‹åŒ– (ä¿®å¤ 404 å…³é”®ç‚¹) ---
storage = GitHubStorage()
if "df_houses" not in st.session_state:
    st.session_state.df_houses = storage.load_data()

@st.cache_resource
def init_ai():
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    # é’ˆå¯¹ v1beta æŠ¥é”™çš„ç»ˆæå¯¹ç­–ï¼šå°è¯•ä¸å¸¦ models/ å‰ç¼€
    return genai.GenerativeModel("gemini-1.5-flash")

model = init_ai()

# --- 4. åŠŸèƒ½å‡½æ•° ---
def process_and_compress_img(uploaded_file):
    """è§£å†³ PNG OSError å¹¶å‹ç¼©å›¾ç‰‡"""
    img = Image.open(uploaded_file)
    if img.mode in ("RGBA", "P"):
        img = img.convert("RGB")
    img.thumbnail((400, 400))
    buf = io.BytesIO()
    img.save(buf, format="JPEG", quality=75)
    return f"data:image/jpeg;base64,{base64.b64encode(buf.getvalue()).decode()}"

def get_ai_commute(loc, s_dest, j_dest):
    """æ¨¡æ‹Ÿ Google Maps é€»è¾‘è·å–æ•°æ®å¹¶æ˜¾ç¤ºå›æ˜¾"""
    prompt = f"""
    ä½ ç°åœ¨æ˜¯ Google Maps äº¤é€š APIã€‚è¯·åˆ†ææ—¥æœ¬é€šå‹¤æ•°æ®ï¼š
    èµ·ç‚¹: {loc}
    ç»ˆç‚¹1: {s_dest}
    ç»ˆç‚¹2: {j_dest}
    å¿…é¡»è¿”å› JSON æ ¼å¼: {{"s_yen":æ•´æ•°,"j_yen":æ•´æ•°,"s_mins":æ•´æ•°,"j_mins":æ•´æ•°}}
    """
    try:
        res = model.generate_content(prompt)
        raw_text = res.text
        
        # è°ƒè¯•å›æ˜¾ï¼šè®©ä½ åœ¨ç•Œé¢ä¸Šç›´æ¥çœ‹åˆ° AI åäº†ä»€ä¹ˆæ•°æ®
        with st.expander("ğŸ” AI åŸå§‹æ•°æ®è°ƒè¯• (ç‚¹å‡»å±•å¼€)"):
            st.code(raw_text)
            
        # æå– JSON å†…å®¹
        json_match = re.search(r'\{.*\}', raw_text, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
        raise ValueError("AI æœªè¿”å›æœ‰æ•ˆ JSON")
    except Exception as e:
        st.error(f"ğŸš¨ äº¤é€šè®¡ç®—å¤±è´¥: {str(e)}") # è¿™é‡Œä¼šæ˜¾ç¤º 404 ç­‰å…·ä½“é”™è¯¯
        return {"s_yen": 200, "j_yen": 200, "s_mins": 99, "j_mins": 99}

# --- 5. UI: è¾“å…¥ä¸è®¾ç½® ---
with st.sidebar:
    st.header("âš™ï¸ ç”Ÿæ´»å‚æ•°")
    base_living = st.number_input("ğŸ” æœˆå›ºå®šç”Ÿæ´»è´¹", value=60000)
    days_school = st.slider("ğŸ« å­¦æ ¡é€šå‹¤å¤©æ•°", 1, 7, 5)
    days_juku = st.slider("ğŸ¨ ç§å¡¾é€šå‹¤å¤©æ•°", 0.0, 7.0, 0.5, step=0.5)
    dest_school = st.text_input("ğŸ“ å­¦æ ¡ä½ç½®", value="ä¸œäº¬éƒ½æ–°å®¿åŒºç™¾äººç”º2-24-12")
    dest_juku = st.text_input("ğŸ“ ç§å¡¾ä½ç½®", value="ä¸œäº¬éƒ½è’å·åŒºè¥¿æ—¥æš®é‡Œ2-12-5")

with st.expander("â• å½•å…¥æ–°æˆ¿æº", expanded=True):
    c1, c2 = st.columns([2, 1])
    with c1:
        name_in = st.text_input("ğŸ  æˆ¿æºåç§°")
        loc_in = st.text_input("ğŸ“ è½¦ç«™å (ä¾‹: è¥¿è»çªªé§…)")
        rent_in = st.number_input("ğŸ’° é¢„ä¼°æœˆç§Ÿ", value=80000)
    with c2:
        up_file = st.file_uploader("ğŸ–¼ï¸ æˆ¿æºç…§ç‰‡", type=['jpg','jpeg','png'])

    if st.button("ğŸš€ AI åˆ†æå¹¶ä¿å­˜", use_container_width=True):
        if loc_in:
            with st.spinner("æ­£åœ¨æ£€ç´¢äº¤é€šæ•°æ®..."):
                commute = get_ai_commute(loc_in, dest_school, dest_juku)
                img_data = process_and_compress_img(up_file) if up_file else ""
                
                # æ‹¼æ¥æ—¶é—´å­—ç¬¦ä¸²æ˜¾ç¤ºåœ¨å¡ç‰‡ä¸Š
                time_info = f"ğŸ«è‡³å­¦æ ¡ {commute['s_mins']}åˆ† | ğŸ¨è‡³ç§å¡¾ {commute['j_mins']}åˆ†"
                
                new_row = pd.DataFrame([{
                    "æˆ¿æºåç§°": name_in or f"{loc_in}æˆ¿æº",
                    "æˆ¿æºä½ç½®": loc_in,
                    "æˆ¿æºå›¾ç‰‡": img_data,
                    "æœˆæˆ¿ç§Ÿ(å††)": rent_in,
                    "ç®¡ç†è´¹(å††)": 5000,
                    "å­¦è´¹(å•ç¨‹)": commute['s_yen'],
                    "å¡¾è´¹(å•ç¨‹)": commute['j_yen'],
                    "é€šå‹¤æ—¶é—´": time_info
                }])
                st.session_state.df_houses = pd.concat([st.session_state.df_houses, new_row], ignore_index=True)
                storage.save_data(st.session_state.df_houses)
                st.rerun()

# --- 6. æ•°æ®åˆ—è¡¨ ---
st.subheader("ğŸ“ æˆ¿æºæ•°æ®æ¸…å•")
st.data_editor(st.session_state.df_houses, use_container_width=True)

if st.button("ğŸš¨ æ¸…ç©ºæ‰€æœ‰æ•°æ®"):
    st.session_state.df_houses = pd.DataFrame(columns=["æˆ¿æºåç§°", "æˆ¿æºä½ç½®", "æˆ¿æºå›¾ç‰‡", "æœˆæˆ¿ç§Ÿ(å††)", "ç®¡ç†è´¹(å††)", "å­¦è´¹(å•ç¨‹)", "å¡¾è´¹(å•ç¨‹)", "é€šå‹¤æ—¶é—´"])
    storage.save_data(st.session_state.df_houses)
    st.rerun()

# --- 7. å¯¹æ¯”æŠ¥å‘Š ---
if not st.session_state.df_houses.empty:
    st.divider()
    st.subheader("ğŸ“Š æˆ¿æºå¯¹æ¯”æŠ¥å‘Š")
    for idx, row in st.session_state.df_houses.iterrows():
        try:
            fare_m = (float(row["å­¦è´¹(å•ç¨‹)"]) * 2 * days_school + float(row["å¡¾è´¹(å•ç¨‹)"]) * 2 * days_juku) * 4.33
            total_m = float(row["æœˆæˆ¿ç§Ÿ(å††)"]) + float(row["ç®¡ç†è´¹(å††)"]) + fare_m + base_living
            
            with st.container(border=True):
                i_col, t_col, b_col = st.columns([1.5, 3, 1.2])
                with i_col:
                    if row["æˆ¿æºå›¾ç‰‡"]: st.image(row["æˆ¿æºå›¾ç‰‡"])
                with t_col:
                    st.markdown(f"### {row['æˆ¿æºåç§°']} ({row['æˆ¿æºä½ç½®']})")
                    st.markdown(f"#### ğŸ’° æœˆæ”¯å‡º: **{int(total_m):,} å††**")
                    st.write(f"ğŸ  æˆ¿ç§Ÿ: {int(float(row['æœˆæˆ¿ç§Ÿ(å††)'])+float(row['ç®¡ç†è´¹(å††)'])):,} | ğŸš‡ æœˆé€šå‹¤è´¹: {int(fare_m):,}")
                    st.write(f"ğŸ•’ **{row['é€šå‹¤æ—¶é—´']}**") # å®æ—¶æ˜¾ç¤ºåˆ†é’Ÿæ•°
                with b_col:
                    m_api = "https://www.google.com/maps/dir/?api=1"
                    s_url = f"{m_api}&origin={urllib.parse.quote(row['æˆ¿æºä½ç½®'])}&destination={urllib.parse.quote(dest_school)}&travelmode=transit"
                    j_url = f"{m_api}&origin={urllib.parse.quote(row['æˆ¿æºä½ç½®'])}&destination={urllib.parse.quote(dest_juku)}&travelmode=transit"
                    st.link_button("ğŸ« å­¦æ ¡åœ°å›¾", s_url, use_container_width=True)
                    st.link_button("ğŸ¨ ç§å¡¾åœ°å›¾", j_url, use_container_width=True)
                    if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"del_{idx}", use_container_width=True):
                        st.session_state.df_houses = st.session_state.df_houses.drop(idx).reset_index(drop=True)
                        storage.save_data(st.session_state.df_houses)
                        st.rerun()
        except: continue
